{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = pd.read_csv('../../../data/epidemicforecasting/epimodel-covid-data/dataimport/ACAPS_as_ef.csv',\n",
    "                 parse_dates=['Date Start'\n",
    "                              #,'Date end intended'\n",
    "                             ]).dropna(subset=['Country'])\n",
    "DATE = '2020_04_03'\n",
    "#complete = pd.read_csv('../../../data/epidemicforecasting/epimodel-covid-data/sources/ Dataset completeness.csv')\n",
    "\n",
    "#complete = complete[~pd.isna(complete['Complete up to date'])]['Country'].append(cm[cm['Country'].str.startswith('US')]['Country'])\n",
    "\n",
    "#cm = cm[cm['Country'].isin(complete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm['Date Start']=pd.to_datetime(cm['Date Start'])\n",
    "cm['Quantity']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-05-25 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm['Date Start'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'COVID 19 Containment measures data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-74879b1ffa84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COVID 19 Containment measures data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date Start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date end intended'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2020_04_03'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset completeness.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Complete up to date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benjaminsmith/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'COVID 19 Containment measures data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "cm = pd.read_csv('COVID 19 Containment measures data.csv',parse_dates=['Date Start','Date end intended']).dropna(subset=['Country'])\n",
    "DATE = '2020_04_03'\n",
    "complete = pd.read_csv('Dataset completeness.csv')\n",
    "\n",
    "complete = complete[~pd.isna(complete['Complete up to date'])]['Country'].append(cm[cm['Country'].str.startswith('US')]['Country'])\n",
    "\n",
    "cm = cm[cm['Country'].isin(complete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jhcc = pd.read_csv('https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "jhd = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "JH2CM = {\n",
    "    'Korea, South':'South Korea',\n",
    "    'Taiwan*':'Taiwan',\n",
    "    ('China','Hong Kong'):'Hong Kong',\n",
    "    ('China','Macau'):'Macau',\n",
    "    ('Netherlands','Faroe Islands'):'Faroe Islands',\n",
    "    'US':'United States'\n",
    "}\n",
    "\n",
    "\n",
    "def jh2cm(c,s):\n",
    "    if c in JH2CM:\n",
    "        return JH2CM[c]\n",
    "    elif (c,s) in JH2CM:\n",
    "        return JH2CM[(c,s)]\n",
    "    return c\n",
    "\n",
    "def pre_jh(jh,val=\"Confirmed Cases\"):\n",
    "    jh['Country/Region'] = [jh2cm(c,s) for c,s in jh[['Country/Region','Province/State']].values]\n",
    "    jh['Country/Region'] = [jh2cm(c,s) for c,s in jh[['Country/Region','Province/State']].values]\n",
    "\n",
    "    jh.drop(['Lat','Long'],axis=1,inplace=True)\n",
    "    jh = jh.groupby('Country/Region').sum().reset_index()\n",
    "    jh = pd.melt(jh,id_vars=['Country/Region'],value_vars=jh.columns[2:],value_name=val,var_name='Date')\n",
    "    jh['Date'] = pd.to_datetime(jh['Date'])\n",
    "    return jh\n",
    "\n",
    "jhcc, jhd = pre_jh(jhcc),pre_jh(jhd,val='Deaths')\n",
    "jhcc['Deaths'] = jhd['Deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_COLS = {\n",
    "    'Symptomatic isolation - targeted':{'contact isolation - symptoms':1,\n",
    "                                        'cohort isolation - symptoms':1},\n",
    "    'Symptomatic isolation - blanket':{'cluster isolation - symptoms':1,\n",
    "                                       'blanket isolation - symptoms':2},\n",
    "    'Asymptomatic isolation - targeted':{'contact isolation - no symptoms':1,\n",
    "                                         'cohort isolation - no symptoms':2},\n",
    "    'Asymptomatic isolation - blanket':{'cluster isolation - no symptoms':1,\n",
    "                                        'blanket isolation - no symptoms':3,\n",
    "                                        'blanket curfew - no symptoms':2,\n",
    "                                        'natural village quarantine':3},\n",
    "    'Domestic travel restriction':{'domestic traveller quarantine':1,\n",
    "                                   'domestic travel ban':2,\n",
    "                                   'total vehicle ban':2},\n",
    "    'Nonessential business suspension':{'general nonessential business suspension':1,\n",
    "                                        'limited nonessential business suspension':0.5,\n",
    "                                   'remote work':0.5},\n",
    "    'International travel restriction':{'international traveller screening - risk countries':1,\n",
    "                                        'international traveller screening - all countries':2,\n",
    "                                        'international traveller quarantine - risk countries':3,\n",
    "                                        'international traveller quarantine - all countries':4,\n",
    "                                        'international travel ban - risk countries':5,\n",
    "                                        'international travel ban - all countries':6},\n",
    "    'Testing':{'testing numbers total':np.nan},\n",
    "    'Contact tracing':{'contacts traced total':np.nan},\n",
    "    'Mask wearing':{'public mask wearing data':np.nan},\n",
    "    'Hand washing':{'public handwashing data':np.nan}\n",
    "    \n",
    "}\n",
    "\n",
    "MIN_COLS = {\n",
    "    'Gatherings banned':['indoor gatherings banned',\n",
    "                        'outdoor gatherings banned']\n",
    "}\n",
    "\n",
    "CUMSUM_COLS = {\n",
    "    'Healthcare specialisation':['clinic specialisation',\n",
    "                                'case transport',\n",
    "                                'quarantine zone',\n",
    "                                'hospital specialisation',\n",
    "                                'healthcare entry screening',\n",
    "                                'remote medical treatment',\n",
    "                                'visiting in hospital banned'],\n",
    "    'Public education and incentives':['risk communication',\n",
    "                                      'community engagement',\n",
    "                                      'coronavirus education activities',\n",
    "                                      'phone line'],\n",
    "    'Assisting people to stay home':['unemployment benefits extension',\n",
    "                                    'eviction moratorium',\n",
    "                                    'isolation allowance',\n",
    "                                    'compulsory isolation'],\n",
    "    'Public cleaning':['public transport cleaning',\n",
    "                      'public facility cleaning'],\n",
    "    'Miscellaneous hygiene measures':['funeral hygiene',\n",
    "                                     'cash cleaning',\n",
    "                                     'cash banned'],\n",
    "    'Public interaction and hygiene':['handshakes banned',\n",
    "                                    'social distancing advice',\n",
    "                                    'stay home advice',\n",
    "                                    'space minimum',\n",
    "                                    'outdoor person density',\n",
    "                                    'indoor person density',\n",
    "                                    'public venue screening',\n",
    "                                    'handwashing encouragement',\n",
    "                                    'public mask encouragement',\n",
    "                                    'public mask supply',\n",
    "                                    'public mask and hygiene supply',\n",
    "                                    'public hand sanitizer supply'],\n",
    "    'School closure':['school closure',\n",
    "                     'university closure',\n",
    "                     'nursery school closure',\n",
    "                     'remote schooling',\n",
    "                     'public transport stopped'],\n",
    "    'Activity cancellation':['activity cancellation - other',\n",
    "                            'sports cancellation',\n",
    "                            'religious activity cancellation',\n",
    "                            'religious activity limitations',\n",
    "                            'weddings canceled',\n",
    "                            'very large event cancellation or postponement',\n",
    "                            'cultural activity limitation',\n",
    "                            'remote cultural content',\n",
    "                            'restaurant limitations',\n",
    "                            'closure of gathering places'],\n",
    "    'Resumption':['public transport resumed',\n",
    "                 'activity resumed',\n",
    "                 'business resumed'],\n",
    "    'Diagnostic criteria loosened':['diagnostic criteria loosened'],\n",
    "    'Diagnostic criteria tightened':['diagnostic criteria tightened']    \n",
    "}\n",
    "\n",
    "TEST_COLS = {    \n",
    "    'Testing criteria':{'test all':1,\n",
    "                       'test symptomatic':0.5,\n",
    "                       'cluster testing':0.3,\n",
    "                       'test contacts':0.1,\n",
    "                       'test cohorts':0.2,\n",
    "                       'test travellers':0.1,\n",
    "                       'test medical staff':0.1,\n",
    "                       'test vulnerable':0.1}\n",
    "}\n",
    "\n",
    "def default_values(kw):\n",
    "    for k, v in {**MAX_COLS,**TEST_COLS}.items():\n",
    "        if (kw in v) and (v[kw]!=np.nan):\n",
    "            return v[kw]\n",
    "    return np.nan\n",
    "\n",
    "def keywords(kws_quants):\n",
    "    res =  pd.DataFrame([(i,j[1]) \n",
    "                         for j in kws_quants.values \n",
    "                         for i in str(j[0]).split(', ')],\n",
    "                        columns=['Keywords','Quantity'])\n",
    "    res['Quantity'] = res['Keywords'].apply(default_values).fillna(res['Quantity'])\n",
    "    return res\n",
    "\n",
    "def sum_kws(kws_quants,tags):\n",
    "    return pd.Series(kws_quants['Keywords'].unique()).isin(tags).sum()\n",
    "\n",
    "def max_kws(kws_quants,tags):\n",
    "    return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].max()\n",
    "\n",
    "def min_kws(kws_quants,tags):\n",
    "    return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].min()\n",
    "\n",
    "def test_kws(kws_quants,tags):\n",
    "    if 'test all' in kws_quants['Keywords']:\n",
    "        return 1\n",
    "    elif 'test symptomatic' in kws_quants['Keywords']:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return kws_quants[kws_quants['Keywords'].isin(tags)]['Quantity'].sum()\n",
    "\n",
    "\n",
    "jdict = {**MAX_COLS,**MIN_COLS,**CUMSUM_COLS,**TEST_COLS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-02 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-03 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-04 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-05 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-06 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-07 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-08 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-09 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-10 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-11 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-12 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-13 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-14 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-15 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-16 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-17 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-18 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-19 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-20 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-21 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-22 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-23 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-24 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-25 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-26 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-27 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-28 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-29 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-30 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-01-31 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-01 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-02 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-03 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-04 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-05 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-06 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-07 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-08 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-09 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-10 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-11 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-12 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-13 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-14 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-15 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-16 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-17 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-18 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-19 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-20 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-21 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-22 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-23 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-24 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-25 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-26 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-27 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-28 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-02-29 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-01 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-02 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-03 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-04 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-05 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-06 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-07 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-08 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-09 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-10 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-11 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-12 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-13 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-14 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-15 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-16 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-17 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-18 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-19 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-20 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-21 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-22 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-23 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-24 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-25 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-26 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-27 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-28 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-29 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-30 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-03-31 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-01 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-02 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-03 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-04 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-05 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-06 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-07 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-08 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-09 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-10 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-11 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-12 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-13 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-14 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-15 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-16 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-17 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-18 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-19 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-20 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-21 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-22 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-23 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-24 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-25 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-26 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-27 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-28 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-29 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-04-30 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-01 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-02 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-03 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-04 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-05 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-06 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-07 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-08 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-09 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-10 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-11 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-12 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-13 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-14 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-15 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-16 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-17 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-18 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-19 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-20 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-21 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-22 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-23 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-24 00:00:00  of  2020-05-25 00:00:00\n",
      "2020-05-25 00:00:00  of  2020-05-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "data_dict = {k:[] for k in jdict.keys()}\n",
    "data_dict['Date'] = []\n",
    "data_dict['Country'] = []\n",
    "\n",
    "for d in pd.date_range(cm['Date Start'].min(),cm['Date Start'].max()):\n",
    "    print(d,' of ',cm['Date Start'].max())\n",
    "    for c in cm['Country'].unique():\n",
    "        data_dict['Country'].append(c)\n",
    "        data_dict['Date'].append(d)\n",
    "        if ((cm['Date Start']<=d)&(cm['Country']==c)).any():\n",
    "            kws_quants = keywords(cm[(cm['Date Start']<=d)&(cm['Country']==c)][['Keywords','Quantity']])\n",
    "        else:\n",
    "            kws_quants = pd.DataFrame({'Keywords':[],'Quantity':[]})\n",
    "        for col in MAX_COLS:\n",
    "            data_dict[col].append(max_kws(kws_quants,MAX_COLS[col].keys()))\n",
    "        for col in CUMSUM_COLS:\n",
    "            data_dict[col].append(sum_kws(kws_quants,CUMSUM_COLS[col]))\n",
    "        for col in TEST_COLS:\n",
    "            data_dict[col].append(test_kws(kws_quants,TEST_COLS[col].keys()))\n",
    "        for col in MIN_COLS:\n",
    "            data_dict[col].append(min_kws(kws_quants,MIN_COLS[col]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmerged_data = pd.DataFrame(data_dict).dropna(subset=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "US_STATES = unmerged_data['Country'][unmerged_data['Country'].str.startswith('US:')].unique()\n",
    "\n",
    "\n",
    "unmerged_data.loc[unmerged_data['Country']=='United States',\n",
    "                  unmerged_data.columns[:-1]] = unmerged_data.loc[unmerged_data['Country'].isin(US_STATES),:].groupby('Date').mean()\n",
    "\n",
    "\n",
    "djh = unmerged_data[unmerged_data['Country'].isin(jhcc['Country/Region'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jhcc.rename(columns={'Country/Region':'Country'},inplace=True)\n",
    "jh_merged_data = djh.merge(jhcc,on=['Date','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unmerged_data.to_csv(f'countermeasures_features_{DATE}.csv')\n",
    "jh_merged_data.to_csv(f'countermeasures_db_johnshopkins_{DATE}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
